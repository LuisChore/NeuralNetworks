{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s0RZyT7H_XW"
      },
      "source": [
        "# MNIST in TF1\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saAy0_EMIbJN",
        "outputId": "95e58ce6-2132-4694-97ca-2129958a4654"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caxSEWbOQDd1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z31hB2QLQRVV"
      },
      "source": [
        "# 1. Import Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8tr3MAQQPS"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data \n",
        "mnist = input_data.read_data_sets(\"input/data/\",one_hot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uOEbocaRw-n"
      },
      "source": [
        "## Checking the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwcUwKxNRqTD",
        "outputId": "c6c027de-6806-4112-ce2d-728b126604c2"
      },
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Zp6YPNDxR-o1",
        "outputId": "59adb05b-e19b-42a4-de5d-2cc87f85fff2"
      },
      "source": [
        "imagedemo = np.reshape(mnist.train.images[24,:],(28,28))\n",
        "plt.imshow(imagedemo,cmap='gray')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fca740c33c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM7ElEQVR4nO3db6xU9Z3H8c9HF3xgScTelCAl226jJs2idiW4SbWpaVpZHwjVQEq0YaPZy4PSUNMHRfugNzEmZtOWrD4g3qqBYmuDASIm6BZJE1s1DVcDiBoKq5BC+FNCDPaJXeXbB/fQXPHOby4zZ+YMfN+v5GZmznfOnG9GP5wz53dmfo4IAbj4XdJ0AwD6g7ADSRB2IAnCDiRB2IEk/qmfG7PNqX+gxyLCky3vas9ue6HtfbYP2F7dzWsB6C13Os5u+1JJf5L0TUmHJe2UtCwi3i6sw54d6LFe7NkXSDoQEe9GxN8k/UbSoi5eD0APdRP2OZL+POHx4WrZJ9getj1me6yLbQHoUs9P0EXEqKRRicN4oEnd7NmPSJo74fHnq2UABlA3Yd8p6WrbX7Q9XdJ3JG2tpy0Adev4MD4iPrK9UtL/SrpU0lMR8VZtnQGoVcdDbx1tjM/sQM/15KIaABcOwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASHc/PLkm2D0r6QNLHkj6KiPl1NAWgfl2FvXJrRJys4XUA9BCH8UAS3YY9JP3W9uu2hyd7gu1h22O2x7rcFoAuOCI6X9meExFHbH9O0nZJ34+IlwvP73xjAKYkIjzZ8q727BFxpLo9IWmLpAXdvB6A3uk47LYvtz3j7H1J35K0t67GANSrm7PxsyRtsX32dX4dES/W0hU+YeXKlcX6o48+2rK2b9++4ronT5YHUm655ZZiHReOjsMeEe9Kur7GXgD0EENvQBKEHUiCsANJEHYgCcIOJNHVFXTnvTGuoJvUAw88UKw/9NBDxfqrr77asjZt2rTiutdee22xvnHjxmJ9ZGSkWD927Fixjvr15Ao6ABcOwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2AbB79+5ifebMmcV66Wuohw4dKq67bdu2Yn3hwoXF+qpVq4r1xx57rFhH/RhnB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEk6pjYEW20G6ueN29esX733XcX6+3G0kv27NlTrLfrHRcO9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATfZ++DJ554oli/9957i/WhoaFi/dSpU+fd01SdOXOmWN+yZUuxftddd9XZDqag4++z237K9gnbeycsu9L2dtv7q9vyrysAaNxUDuPXSTr3MqrVknZExNWSdlSPAQywtmGPiJclnXucuEjS+ur+ekmLa+4LQM06vTZ+VkQcre4fkzSr1RNtD0sa7nA7AGrS9RdhIiJKJ94iYlTSqJT3BB0wCDodejtue7YkVbcn6msJQC90GvatkpZX95dLeq6edgD0StvDeNvPSPq6pCHbhyX9RNIjkjbavk/SIUlLe9nkoJs+fXqxfv311xfrL774YrHey3H0dl577bVifc6cOX3qBN1qG/aIWNai9I2aewHQQ1wuCyRB2IEkCDuQBGEHkiDsQBL8lHQNZsyYUazfeOONxfrixYP71YLTp08X61dccUWfOkG32LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs9fgjjvu6Gr9gwcP1tNIB+65555i/bbbbivW16xZU6yvW7euZe2ll14qrvv0008X6zg/7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2WvwyiuvdLX+5s2bi/UXXnihWN+/f3/H216xYkXH60rS/fff3/G677//frHOOHu92LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiP5tzO7fxvqo3ZTNGzZsKNaXLi3PeN3P/0bnancNQbvv4s+bN69l7ZJLyvua6667rljH5CLCky1vu2e3/ZTtE7b3Tlg2YvuI7V3V3+11NgugflM5jF8naeEky9dExA3V37Z62wJQt7Zhj4iXJZ3qQy8AeqibE3Qrbe+pDvNntnqS7WHbY7bHutgWgC51Gva1kr4k6QZJRyX9rNUTI2I0IuZHxPwOtwWgBh2FPSKOR8THEXFG0i8kLai3LQB16yjstmdPePhtSXtbPRfAYGg7zm77GUlflzQk6bikn1SPb5AUkg5KWhERR9tu7CIdZ++1JUuWFOuXXXZZx6/93nvvFevdfld/ZGSkZW316tXFdW+66aZifffu3Z20dNFrNc7e9scrImLZJIuf7LojAH3F5bJAEoQdSIKwA0kQdiAJwg4kwU9JXwCeffbZplvoiXZfDW43FTZDb+eHPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4OwbWNddc03QLFxX27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs6KkPP/yw6RZQYc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo6eKv3m/cMPP9zHTtB2z257ru3f2X7b9lu2V1XLr7S93fb+6nZm79sF0KmpHMZ/JOmHEfFlSf8u6Xu2vyxptaQdEXG1pB3VYwADqm3YI+JoRLxR3f9A0juS5khaJGl99bT1khb3qkkA3Tuvz+y2vyDpK5L+KGlWRBytSsckzWqxzrCk4c5bBFCHKZ+Nt/0ZSZsk/SAiTk+sRURIisnWi4jRiJgfEfO76hRAV6YUdtvTNB70X0XE5mrxcduzq/psSSd60yKAOrQ9jLdtSU9Keicifj6htFXSckmPVLfP9aRDXNAOHDjQsrZz587iuldddVXd7aQ2lc/sX5X0XUlv2t5VLXtQ4yHfaPs+SYckLe1NiwDq0DbsEfEHSW5R/ka97QDoFS6XBZIg7EAShB1IgrADSRB2IAm+4orGjF942dqtt95arA8NDRXrJ0+ePO+eLmbs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZ0Zjnn3++WF+wYEGxvmTJkmJ97dq1593TxYw9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTg7GjM2NtbV+nfeeWex/vjjj7esnTlzpqttX4jYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEm73292250r6paRZkkLSaET8j+0RSf8l6S/VUx+MiG1tXqu8MaQyffr0Yn3Dhg3Fervvs5fqmzZtKq57IYuISWddnspFNR9J+mFEvGF7hqTXbW+vamsi4qd1NQmgd6YyP/tRSUer+x/YfkfSnF43BqBe5/WZ3fYXJH1F0h+rRStt77H9lO2ZLdYZtj1mu7trIwF0Zcpht/0ZSZsk/SAiTktaK+lLkm7Q+J7/Z5OtFxGjETE/IubX0C+ADk0p7LanaTzov4qIzZIUEccj4uOIOCPpF5LKvw4IoFFtw27bkp6U9E5E/HzC8tkTnvZtSXvrbw9AXaYy9HazpN9LelPS2e8FPihpmcYP4UPSQUkrqpN5pddi6A3osVZDb23DXifCDvReq7BzBR2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJfk/ZfFLSoQmPh6plg2hQexvUviR661Sdvf1zq0Jfv8/+qY3bY4P623SD2tug9iXRW6f61RuH8UAShB1Ioumwjza8/ZJB7W1Q+5LorVN96a3Rz+wA+qfpPTuAPiHsQBKNhN32Qtv7bB+wvbqJHlqxfdD2m7Z3NT0/XTWH3gnbeycsu9L2dtv7q9tJ59hrqLcR20eq926X7dsb6m2u7d/Zftv2W7ZXVcsbfe8KffXlfev7Z3bbl0r6k6RvSjosaaekZRHxdl8bacH2QUnzI6LxCzBsf03SXyX9MiL+tVr235JORcQj1T+UMyPiRwPS24ikvzY9jXc1W9HsidOMS1os6T/V4HtX6Gup+vC+NbFnXyDpQES8GxF/k/QbSYsa6GPgRcTLkk6ds3iRpPXV/fUa/5+l71r0NhAi4mhEvFHd/0DS2WnGG33vCn31RRNhnyPpzxMeH9Zgzfcekn5r+3Xbw003M4lZE6bZOiZpVpPNTKLtNN79dM404wPz3nUy/Xm3OEH3aTdHxL9J+g9J36sOVwdSjH8GG6Sx0ylN490vk0wz/g9NvnedTn/erSbCfkTS3AmPP18tGwgRcaS6PSFpiwZvKurjZ2fQrW5PNNzPPwzSNN6TTTOuAXjvmpz+vImw75R0te0v2p4u6TuStjbQx6fYvrw6cSLbl0v6lgZvKuqtkpZX95dLeq7BXj5hUKbxbjXNuBp+7xqf/jwi+v4n6XaNn5H/P0k/bqKHFn39i6Td1d9bTfcm6RmNH9b9v8bPbdwn6bOSdkjaL+klSVcOUG8bND619x6NB2t2Q73drPFD9D2SdlV/tzf93hX66sv7xuWyQBKcoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4O8JoSi2leCLEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGsfEvs2Sbxn",
        "outputId": "3a76d2ed-c04c-4037-803b-11d69e76eac5"
      },
      "source": [
        "def print_image(img):\n",
        "  s = '\\n'.join([''.join(['{:4}'.format(int(round(item * 255))) for item in row]) for row in img])\n",
        "  print(s)\n",
        "\n",
        "print_image(imagedemo)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 108 254 215 196   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0 121 252 194 199 238 152  24   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0 209 226  31   0 182 254 109   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  72 254  89   0   0 136 254 109   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0 156 254  18   0   0   0 254 173   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   6 203 182   0   0   0   0 197 200   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  19 254  78   0   0   0   0 183 199   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  97 254  46   0   0   0  92 254 141 160  92   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  38 254 220 148 110 110 213 254 254 254 144   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   6 169 255 254 254 254 254 196 163 208 210   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  85  92  92  59   0   0 128 248  47   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 254 125   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 121 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  37 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 201 189   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 200 254  20   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 123 254 105   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  71 254 187   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6 169 254  83   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x8Sj61tUki3"
      },
      "source": [
        "# 2. Set up the architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_0dhPDSr7d"
      },
      "source": [
        "def neural_network_model(\n",
        "    n_nodes_input = 784,\n",
        "    n_nodes_hl1 = 500,\n",
        "    n_nodes_hl2 = 500,\n",
        "    n_nodes_hl3 = 500,\n",
        "    n_classes = 10\n",
        "\n",
        "    ):\n",
        "    \n",
        "    # Input & Output\n",
        "    # placeholders, data that we pass to the network, and validate parameters\n",
        "    # None because we don't specify the batch size \n",
        "    x = tf.placeholder('float',[None,n_nodes_input])\n",
        "    y = tf.placeholder('float')\n",
        "\n",
        "\n",
        "    # Declare Variables (weights & Bias)\n",
        "    hidden_layer1 = {'weights':tf.Variable(tf.random_normal([n_nodes_input,n_nodes_hl1])),\n",
        "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "\n",
        "    hidden_layer2 = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])),\n",
        "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "\n",
        "    hidden_layer3 = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
        "                     'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "    \n",
        "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
        "                     'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "\n",
        "\n",
        "    # Declare the Architecture \n",
        "    l1 = tf.add(tf.matmul(x,hidden_layer1['weights']),hidden_layer1['biases'])\n",
        "    l1 = tf.nn.relu(l1)\n",
        "\n",
        "    l2 = tf.add(tf.matmul(l1,hidden_layer2['weights']),hidden_layer2['biases'])\n",
        "    l2 = tf.nn.relu(l2)\n",
        "\n",
        "    l3 = tf.add(tf.matmul(l2,hidden_layer3['weights']),hidden_layer3['biases'])\n",
        "    l3 = tf.nn.relu(l3)\n",
        "\n",
        "    output = tf.add(tf.matmul(l3,output_layer['weights']),output_layer['biases'])\n",
        "\n",
        "\n",
        "    # Declare Cost Function & Optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output,labels = y))\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "\n",
        "    #Return only the declaration of the network components, they're used for TF\n",
        "    return dict(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        output=output,\n",
        "        cost=cost,\n",
        "        optimizer=optimizer\n",
        "    )\n",
        "\n",
        "\n",
        "neural_network_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYfKhyWnp-_A"
      },
      "source": [
        "# 3. Training & Testing Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdrQrg8mqDH4",
        "outputId": "82f7b911-a460-4dab-c9b8-c4bde578ef2c"
      },
      "source": [
        "def train_neural_network(DNN,epochs = 10,batch_size = 100):\n",
        "  #All tf operations run inside a session\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer()) #async \n",
        "    for epoch in range(epochs):\n",
        "      epoch_loss = 0\n",
        "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "        epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
        "        feed_dict = {DNN[\"x\"]:epoch_x,DNN[\"y\"]:epoch_y}\n",
        "        _,c,prediction,y = sess.run([DNN['optimizer'],DNN['cost'],\n",
        "                                     DNN['output'],DNN['y']],\n",
        "                                    feed_dict = feed_dict)\n",
        "        epoch_loss += c\n",
        "      print('Epoch',epoch,'completed out of',epochs,'loss:',epoch_loss)\n",
        "\n",
        "    #TESTING WITH VALUES NOT SEEN \n",
        "    #not passing the optimzer don't change the variables\n",
        "    prediction,y = sess.run([DNN['output'],DNN['y']],feed_dict={DNN['x']:mnist.test.images,DNN['y']:mnist.test.labels})\n",
        "    correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "    print('Accuracy:',accuracy.eval())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DNN = neural_network_model()\n",
        "train_neural_network(DNN)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 10 loss: 1524437.792755127\n",
            "Epoch 1 completed out of 10 loss: 365140.3566017151\n",
            "Epoch 2 completed out of 10 loss: 193134.44923305511\n",
            "Epoch 3 completed out of 10 loss: 114508.72091591358\n",
            "Epoch 4 completed out of 10 loss: 69179.38691204786\n",
            "Epoch 5 completed out of 10 loss: 44747.30611246022\n",
            "Epoch 6 completed out of 10 loss: 28086.78779780239\n",
            "Epoch 7 completed out of 10 loss: 20720.39835165441\n",
            "Epoch 8 completed out of 10 loss: 20773.15589890063\n",
            "Epoch 9 completed out of 10 loss: 18109.92438607119\n",
            "Accuracy: 0.9516\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}