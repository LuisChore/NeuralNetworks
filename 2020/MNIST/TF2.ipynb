{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTjGkMY0p8n"
      },
      "source": [
        "# MNIST in TF2\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBEi67GZ10PC"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtcH1aKa14vl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "#all the examples in TF2 need preprocessing, they are not included \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuKGFxX12cmN"
      },
      "source": [
        "# 1. Import Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQKud8o2f2q"
      },
      "source": [
        "# TF now only has the tools to create architectures\n",
        "# Keras has all the datasets & API\n",
        "mnist = tf.keras.datasets.mnist  \n",
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSdgVKA05HdK"
      },
      "source": [
        "## Checking the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "75fpPj2U5NQ1",
        "outputId": "df8d897e-8966-4bfa-9f4f-9b2c5d9a0256"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "imagedemo = x_train[24]\n",
        "plt.imshow(imagedemo,cmap = 'gray')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6b20f4f748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu_tlRcW5nxP",
        "outputId": "4df7ab93-ff1a-47f6-ce6a-3dc8168f0122"
      },
      "source": [
        "def print_image(img):\n",
        "  s = '\\n'.join([''.join(['{:4}'.format(int(round(item * 255))) for item in row]) for row in img])\n",
        "  print(s)\n",
        "\n",
        "print_image(imagedemo)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0423305661014025   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   05023564770555901275   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   073956349564770647702295   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   011475647706477044370 510   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0102041820647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   03723064770647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0257556247564770647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   024735632406477052020647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   03060150452499038505604356477064770277958925647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0104555508064770647706094539015943510208160647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0178511220112207650   0   0   08160647706477024480   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   04845586506477044370   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356477028050   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356451516065   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   094351377013770114756630214205635521420535579054131019890   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   015301045535955622206477064770632406018064770647706477059415609456477035190   0   0   0   0   0   0\n",
            "   0   0   0   0   0   05865425856477064770647706477058395581404717535190351903519035190351903519011220   0   0   0   0   0   0\n",
            "   0   0   0   0   0   02881564770647706477045645163201275   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   08160532954666524735   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzjneJA5zYu"
      },
      "source": [
        "## Preprocessing the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elrh7BR05tEl",
        "outputId": "7971956e-9cbc-4ec1-87e4-3eadf6c97f26"
      },
      "source": [
        "''' Reshape the input for the DNN '''\n",
        "# Only TF1 had tools for preprocessing, now all is with numpy and sklearn\n",
        "x_train = x_train.reshape(-1,28*28).astype('float32')  # in TF2 is important the data type for TF2 \n",
        "x_test = x_test.reshape(-1,28*28).astype('float32')\n",
        "print(x_train.shape)\n",
        "x_train "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAZOlsn7u8w",
        "outputId": "9f5bca7f-5435-4026-8400-6b78403c4958"
      },
      "source": [
        "''' Codify the outputs from CATEGORICAL to ONE HOT '''\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train = y_train.reshape(len(y_train),1)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test = y_test.reshape(len(y_test),1)\n",
        "y_test_one_hot = onehot_encoder.fit_transform(y_test)\n",
        "y_train_onehot.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UicKx8P884pf"
      },
      "source": [
        "# 2. Set up the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM2ExtuT89__",
        "outputId": "8ba89714-3ec5-4896-f3af-5c9d6ce371b6"
      },
      "source": [
        "class DNN_Model(object):\n",
        "  def __init__(self,\n",
        "              n_nodes_input = 784,\n",
        "              n_nodes_hl1 = 500,\n",
        "              n_nodes_hl2 = 500,\n",
        "              n_nodes_hl3 = 500,\n",
        "              n_classes = 10):\n",
        "    # Declare DNN Variables with numpy\n",
        "    self.hl1W = tf.Variable(np.random.rand(n_nodes_input,n_nodes_hl1),name = \"hl1weights\",dtype = \"float32\")\n",
        "    self.hl1B = tf.Variable(np.random.rand(n_nodes_hl1),name = \"hl1bias\",dtype = \"float32\")\n",
        "    self.hl2W = tf.Variable(np.random.rand(n_nodes_hl1,n_nodes_hl2),name = \"hl2weights\",dtype = \"float32\")\n",
        "    self.hl2B = tf.Variable(np.random.rand(n_nodes_hl2),name = \"hl2bias\",dtype = \"float32\")\n",
        "    self.hl3W = tf.Variable(np.random.rand(n_nodes_hl2,n_nodes_hl3),name = \"hl3weights\",dtype = \"float32\")\n",
        "    self.hl3B = tf.Variable(np.random.rand(n_nodes_hl3),name = \"hl3bias\",dtype = \"float32\")\n",
        "    self.outW = tf.Variable(np.random.rand(n_nodes_hl3,n_classes),name = \"outweights\",dtype = \"float32\")\n",
        "    self.outB = tf.Variable(np.random.rand(n_classes),name = \"outbias\",dtype = \"float32\")\n",
        "    # Auxiliar List\n",
        "    self.trainable_variables = [self.hl1W,self.hl1B,self.hl2W,self.hl2B,self.hl3W,self.hl3B,self.outW,self.outB]\n",
        "\n",
        "  def __call__(self,x):\n",
        "    # Declare architecture\n",
        "    l1 = tf.add(tf.matmul(x,self.hl1W),self.hl1B)\n",
        "    l1 = tf.nn.relu(l1)\n",
        "\n",
        "    l2 = tf.add(tf.matmul(l1,self.hl2W),self.hl2B)\n",
        "    l2 = tf.nn.relu(l2)\n",
        "\n",
        "    l3 = tf.add(tf.matmul(l2,self.hl3W),self.hl3B)\n",
        "    l3 = tf.nn.relu(l3)\n",
        "\n",
        "    output = tf.add(tf.matmul(l3,self.outW),self.outB)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "DNN = DNN_Model()   # model declaration\n",
        "DNN(x_train[24:30]) # forward propagation"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 10), dtype=float32, numpy=\n",
              "array([[1.71623678e+11, 1.70397237e+11, 1.74620508e+11, 1.73351322e+11,\n",
              "        1.72562088e+11, 1.68280031e+11, 1.68686830e+11, 1.74971503e+11,\n",
              "        1.69804087e+11, 1.67246299e+11],\n",
              "       [3.19618154e+11, 3.17333275e+11, 3.25199004e+11, 3.22835743e+11,\n",
              "        3.21365770e+11, 3.13391120e+11, 3.14148585e+11, 3.25853381e+11,\n",
              "        3.16229157e+11, 3.11465705e+11],\n",
              "       [1.06098754e+11, 1.05340387e+11, 1.07951243e+11, 1.07166999e+11,\n",
              "        1.06678927e+11, 1.04031650e+11, 1.04283038e+11, 1.08168528e+11,\n",
              "        1.04973779e+11, 1.03392633e+11],\n",
              "       [3.61657860e+11, 3.59072629e+11, 3.67972385e+11, 3.65298516e+11,\n",
              "        3.63635540e+11, 3.54612085e+11, 3.55468771e+11, 3.68713138e+11,\n",
              "        3.57823021e+11, 3.52433275e+11],\n",
              "       [3.26261473e+11, 3.23929309e+11, 3.31958223e+11, 3.29546138e+11,\n",
              "        3.28045593e+11, 3.19905137e+11, 3.20678396e+11, 3.32626330e+11,\n",
              "        3.22801959e+11, 3.17939909e+11],\n",
              "       [1.23629273e+11, 1.22745864e+11, 1.25788013e+11, 1.24873908e+11,\n",
              "        1.24305293e+11, 1.21220727e+11, 1.21513566e+11, 1.26041063e+11,\n",
              "        1.22318635e+11, 1.20475902e+11]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpOY1jObHHdF"
      },
      "source": [
        "# 3. Choose optimizer & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZC_h7WFHiW9"
      },
      "source": [
        "'''Optmizer'''\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001)\n",
        "\n",
        "'''Metrics'''\n",
        "# Declare which one is going to be our cost function \n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de4ud0fEHuZo"
      },
      "source": [
        "# 4. Training & Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2xHHD14HyGE"
      },
      "source": [
        "@tf.function #NOT EAGER EXECUTION\n",
        "def train_step(model,data,labels):\n",
        "  with tf.GradientTape() as tape: # in tape the gradients are going to be saved\n",
        "    predictions = model(data) # forward propagation\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,predictions)) # compute cost function\n",
        "\n",
        "  #optimize\n",
        "  gradients = tape.gradient(loss,model.trainable_variables)\n",
        "  capped_grads_and_vars = [(grad,model.trainable_variables[index]) for index,grad in enumerate(gradients)]\n",
        "  #adjust variables\n",
        "  optimizer.apply_gradients(capped_grads_and_vars)\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels,predictions)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRenkYxzQnbm"
      },
      "source": [
        "@tf.function\n",
        "def test_step(model,data,labels):\n",
        "  predictions = model(data)\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,predictions))\n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels,predictions)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iAiU84hWKJ-"
      },
      "source": [
        "def fitting(model,train_x,train_y,test_x,test_y,epochs,n_batch,batch_size):\n",
        "  for epoch in range(epochs):\n",
        "    i = 0\n",
        "    while i + batch_size < len(train_x) or i + batch_size < batch_size * n_batch:\n",
        "      start = i\n",
        "      end = start + batch_size\n",
        "      batch_x = train_x[start:end]\n",
        "      batch_y = train_y[start:end]\n",
        "      train_step(model,batch_x,batch_y)\n",
        "      i += batch_size\n",
        "    test_step(model,test_x,test_y)\n",
        "    template = 'Epoch {},Loss:{},Accuracy:{},Test Loss:{}, Test Accuracy:{}'\n",
        "    print(template.format(epoch+1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result() * 100))\n",
        "    train_loss.reset_states() \n",
        "    train_accuracy.reset_states()\n",
        "    \n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states() \n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzdRPEkyY12f",
        "outputId": "59de0867-3201-43ab-8a1e-c5d75147724a"
      },
      "source": [
        "fitting(DNN,x_train,y_train_onehot,x_test,y_test_one_hot,10,600,100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1,Loss:240179456.0,Accuracy:9.94991683959961,Test Loss:143054624.0, Test Accuracy:8.920000076293945\n",
            "Epoch 2,Loss:34730192.0,Accuracy:13.055091857910156,Test Loss:4398840.0, Test Accuracy:30.970001220703125\n",
            "Epoch 3,Loss:915240.25,Accuracy:54.684471130371094,Test Loss:834618.3125, Test Accuracy:57.290000915527344\n",
            "Epoch 4,Loss:262659.4375,Accuracy:69.72454071044922,Test Loss:173236.53125, Test Accuracy:74.87999725341797\n",
            "Epoch 5,Loss:190536.609375,Accuracy:74.74457550048828,Test Loss:100237.109375, Test Accuracy:82.16999816894531\n",
            "Epoch 6,Loss:123406.171875,Accuracy:79.93321990966797,Test Loss:201471.390625, Test Accuracy:71.5\n",
            "Epoch 7,Loss:81124.0234375,Accuracy:83.39733123779297,Test Loss:77863.5234375, Test Accuracy:82.6300048828125\n",
            "Epoch 8,Loss:46949.875,Accuracy:86.92654418945312,Test Loss:31633.5234375, Test Accuracy:89.42000579833984\n",
            "Epoch 9,Loss:27093.49609375,Accuracy:88.97663116455078,Test Loss:17833.66796875, Test Accuracy:91.00999450683594\n",
            "Epoch 10,Loss:15386.69140625,Accuracy:90.31886291503906,Test Loss:10127.5810546875, Test Accuracy:92.08999633789062\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}