{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvNetTF2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFM5tInHg03P"
      },
      "source": [
        "# ConvNet MNIST Tensorflow2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcbhXlg3g1Hm"
      },
      "source": [
        "  %tensorflow_version 2.x\n",
        "  import tensorflow as tf\n",
        "  import numpy as np \n",
        "  import matplotlib.pyplot as plt \n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  %matplotlib inline \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyRvk2xsjQ0x"
      },
      "source": [
        "# 1. Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkdid2-GhlAU"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSZ5tZu8jUbz"
      },
      "source": [
        "### Checking the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "oH9vTidPjZf1",
        "outputId": "db93f45f-b001-48c7-a953-0b6455f5e65f"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train[133])\n",
        "imagedemo = x_train[133]\n",
        "plt.imshow(imagedemo,cmap = 'gray')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 28, 28)\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3004ad8748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvKMBP5GnXbV"
      },
      "source": [
        "### Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG-FsRlBncFI",
        "outputId": "377e33b3-ee59-4215-b73f-5d7167c189e0"
      },
      "source": [
        "# one hot enconding\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train = y_train.reshape(len(y_train),1)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test = y_test.reshape(len(y_test),1)\n",
        "y_test_onehot = onehot_encoder.fit_transform(y_test)\n",
        "y_train_onehot.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pigwJHvwqfyg"
      },
      "source": [
        "# 2. Set up Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtmawbusGm_"
      },
      "source": [
        "### ConvNet functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rCEFU-sK7R"
      },
      "source": [
        "# doesn't reduce the image size\n",
        "def conv2d(x,W,strides,padding,name = None):\n",
        "  '''\n",
        "    filters: window_size * depth * output_size \n",
        "  '''\n",
        "  return tf.nn.conv2d(input = x,filters = W,strides = strides,padding = padding,name = name)\n",
        "\n",
        "# reduce size of the image to the half \n",
        "def max_pool2d(x,ks,st):\n",
        "  '''\n",
        "    ksize = [batch,x,y,depth] ; filter size for maxpooling \n",
        "  '''\n",
        "  return tf.nn.max_pool(input = x,ksize = ks,strides = st,padding = 'SAME')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3YS0Yzx0Mwx",
        "outputId": "aceaf4ff-6a3b-4548-e4d0-9d08f6d7f2a1"
      },
      "source": [
        "class DNN_Model(object):\n",
        "  def __init__(self,\n",
        "               n_classes = 10):\n",
        "    ''' First convolution kernel '''\n",
        "    # (5,5,1) size of the conv window, 1 because is B&W\n",
        "    # 32 is the size of the new dimention. it represents the number of filters\n",
        "    self.hl1W = tf.Variable(np.random.rand(5,5,1,32),name = 'hl1weights',dtype = 'float32')\n",
        "    self.hl1B = tf.Variable(np.random.rand(32),name = 'hl1bias', dtype = 'float32')\n",
        "    \n",
        "    ''' Second convolution kernel ''' \n",
        "    # (5,5,32) size of the conv window, 32 because is the current dimention\n",
        "    # 64 is the size of the new dimention. it represents the number of filters\n",
        "    self.hl2W = tf.Variable(np.random.rand(5,5,32,64),name = 'hl2weights',dtype = 'float32')\n",
        "    self.hl2B = tf.Variable(np.random.rand(64),name = 'hl2bias', dtype = 'float32')\n",
        "\n",
        "    ''' DNN '''\n",
        "    self.hl3W = tf.Variable(np.random.rand(7 * 7 * 64, 1024),name = 'hl3weights',dtype = 'float32')\n",
        "    self.hl3B = tf.Variable(np.random.rand(1024),name = 'hl3bias',dtype = 'float32')\n",
        "\n",
        "    self.outW = tf.Variable(np.random.rand(1024,10),name = 'outweights', dtype = 'float32')\n",
        "    self.outB = tf.Variable(np.random.rand(10),name = 'outbias', dtype = 'float32')\n",
        "    \n",
        "    self.trainable_variables = [self.hl1W,self.hl1B,self.hl2W,self.hl2B,self.hl3W,self.hl3B,self.outW,self.outB]\n",
        "\n",
        "  def __call__(self,x):\n",
        "    x = tf.cast(x,tf.float32)\n",
        "    img = tf.reshape(x,shape=[-1,28 , 28, 1])\n",
        "    # -1 correspond to the batch index, batch number is respeted by -1 value\n",
        "\n",
        "    ''' Conv layers '''\n",
        "    #stride = [batch_stride = 1 (image by image, without skip any),x,y,filter_stride = 1]\n",
        "    #  => (28*28*1)\n",
        "    l1 = conv2d(img,self.hl1W,[1,1,1,1],'SAME') \n",
        "    l1 = tf.add(l1,self.hl1B)\n",
        "    l1 = tf.nn.relu(l1)\n",
        "    l1 = max_pool2d(l1,[1,2,2,1],[1,2,2,1])\n",
        "    # (14*14*32) =>\n",
        "\n",
        "    # => (14*14*32)\n",
        "    l2 = conv2d(l1,self.hl2W,[1,1,1,1],'SAME')\n",
        "    l2 = tf.add(l2,self.hl2B)\n",
        "    l2 = tf.nn.relu(l2)\n",
        "    l2 = max_pool2d(l2,[1,2,2,1],[1,2,2,1])\n",
        "    # (7*7*64) =>\n",
        "\n",
        "    ''' Flatten '''\n",
        "    l2 = tf.reshape(l2,[-1,7*7*64])\n",
        "\n",
        "    ''' DNN ''' \n",
        "    l3 = tf.add(tf.matmul(l2,self.hl3W),self.hl3B)\n",
        "    l3 = tf.nn.relu(l3)\n",
        "\n",
        "    output = tf.add(tf.matmul(l3,self.outW),self.outB)\n",
        "\n",
        "    return output\n",
        "\n",
        "DNN = DNN_Model()   # model declaration\n",
        "DNN(x_train[24:30]) # forward propagation"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 10), dtype=float32, numpy=\n",
              "array([[1.73788381e+11, 1.82537208e+11, 1.89222699e+11, 1.83482139e+11,\n",
              "        1.77060348e+11, 1.79049038e+11, 1.79505365e+11, 1.82959948e+11,\n",
              "        1.82869066e+11, 1.79857949e+11],\n",
              "       [3.06972066e+11, 3.22445804e+11, 3.34207025e+11, 3.24107665e+11,\n",
              "        3.12743690e+11, 3.16289253e+11, 3.17093577e+11, 3.23200942e+11,\n",
              "        3.22984280e+11, 3.17695525e+11],\n",
              "       [1.13032380e+11, 1.18727328e+11, 1.23080761e+11, 1.19337689e+11,\n",
              "        1.15169370e+11, 1.16457275e+11, 1.16752409e+11, 1.18989734e+11,\n",
              "        1.18967198e+11, 1.16992426e+11],\n",
              "       [3.41313978e+11, 3.58483296e+11, 3.71595510e+11, 3.60357134e+11,\n",
              "        3.47727462e+11, 3.51646908e+11, 3.52533217e+11, 3.59340442e+11,\n",
              "        3.59096254e+11, 3.53232519e+11],\n",
              "       [3.13743770e+11, 3.29572155e+11, 3.41587296e+11, 3.31286020e+11,\n",
              "        3.19638798e+11, 3.23278668e+11, 3.24099572e+11, 3.30318774e+11,\n",
              "        3.30111844e+11, 3.24719477e+11],\n",
              "       [1.35164207e+11, 1.41958906e+11, 1.47174277e+11, 1.42685929e+11,\n",
              "        1.37720627e+11, 1.39251466e+11, 1.39593941e+11, 1.42286062e+11,\n",
              "        1.42232601e+11, 1.39884757e+11]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQWoUKanL0mw"
      },
      "source": [
        "# 3. Choose Optimizer & Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8_kFJsy_KDD"
      },
      "source": [
        "''' Optimizer '''\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.01)\n",
        "\n",
        "''' Metrics '''\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsOqfRLTMt4h"
      },
      "source": [
        "\n",
        "# 4. Training & Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7qSZDAPMwP7"
      },
      "source": [
        "# compute gradient and adjust weights and biases \n",
        "@tf.function #compile\n",
        "def train_step(model,data,labels):\n",
        "  with tf.GradientTape() as tape: # memory to save gradients\n",
        "    predictions = model(data)     # forward propagation\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,predictions)) # compute error\n",
        "  \n",
        "  gradients = tape.gradient(loss,model.trainable_variables) #compute gradients with respect with 'trainable_variables'\n",
        "  grads_and_vars_pairs = [(grad,model.trainable_variables[index]) for index,grad in enumerate(gradients)]\n",
        "  optimizer.apply_gradients(grads_and_vars_pairs) # adjust weights and biases\n",
        "\n",
        "  ''' compute metrics '''\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels,predictions)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FieKZ74uTNPf"
      },
      "source": [
        "@tf.function\n",
        "def test_step(model,data,labels):\n",
        "  predictions = model(data)\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels,predictions))\n",
        "  \n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels,predictions)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcgnLBd2Tlcm"
      },
      "source": [
        "def fitting(model,train_x,train_y,test_x,test_y,epochs,n_batch,batch_size):\n",
        "  for epoch in range(epochs):\n",
        "    i = 0\n",
        "    while i + batch_size < len(train_x) or i + batch_size < batch_size * n_batch:\n",
        "      start = i \n",
        "      end = i + batch_size \n",
        "      batch_x = train_x[start:end]\n",
        "      batch_y = train_y[start:end]\n",
        "      train_step(model,batch_x,batch_y)\n",
        "      i += batch_size \n",
        "    test_step(model,test_x,test_y)\n",
        "    template = 'Epoch {},Loss:{},Accuracy:{},Test Loss:{}, Test Accuracy:{}'\n",
        "    print(template.format(epoch+1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result() * 100))\n",
        "    train_loss.reset_states() \n",
        "    train_accuracy.reset_states()\n",
        "    \n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VGNo1BvUy0R",
        "outputId": "253b12f2-081d-4203-dc65-dfe62dfac8db"
      },
      "source": [
        "fitting(DNN,x_train,y_train_onehot,x_test,y_test_onehot,10,600,100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1,Loss:277404480.0,Accuracy:60.711185455322266,Test Loss:1322910.25, Test Accuracy:71.93000030517578\n",
            "Epoch 2,Loss:928010.0625,Accuracy:73.46577453613281,Test Loss:538629.3125, Test Accuracy:74.98999786376953\n",
            "Epoch 3,Loss:214721.671875,Accuracy:82.87979888916016,Test Loss:240383.359375, Test Accuracy:74.76000213623047\n",
            "Epoch 4,Loss:59510.87109375,Accuracy:87.82137298583984,Test Loss:36335.37890625, Test Accuracy:89.1300048828125\n",
            "Epoch 5,Loss:21549.5390625,Accuracy:90.99665832519531,Test Loss:17452.88671875, Test Accuracy:90.01000213623047\n",
            "Epoch 6,Loss:10263.2197265625,Accuracy:92.54090118408203,Test Loss:7322.0576171875, Test Accuracy:93.69000244140625\n",
            "Epoch 7,Loss:6070.01611328125,Accuracy:93.7228775024414,Test Loss:5052.68798828125, Test Accuracy:94.18000030517578\n",
            "Epoch 8,Loss:4206.89892578125,Accuracy:94.34056854248047,Test Loss:3888.464111328125, Test Accuracy:94.73999786376953\n",
            "Epoch 9,Loss:2966.377197265625,Accuracy:94.97161865234375,Test Loss:2668.124755859375, Test Accuracy:95.56999969482422\n",
            "Epoch 10,Loss:2225.27197265625,Accuracy:95.47579193115234,Test Loss:2304.845703125, Test Accuracy:95.68000030517578\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}